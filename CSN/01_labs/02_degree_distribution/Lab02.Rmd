---
title: "Complex & Social Networks: Lab 02 Report"
author:
  - Francisco Javier Jurado Moreno
  - Sergio Mosquera Dopico
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Introduction

#Results

#Discussion

#Methods

```{r cars, include=FALSE}
# Load the igraph library and require the packages stats4 (mle) & VGAM (Riemman-zeta)
require(igraph)
require(knitr)
require('stats4')
require('VGAM')
require(kableExtra)
```

```{r, include=FALSE}
# Read the list of languages from file
languages = read.table("list.txt",
              header = TRUE,               # this is to indicate the first line of the file contains the names of the columns instead of the real data
              as.is = c("language","file") # this is need to have the cells treated as real strings and not as categorial data.
            )

# Read the language files from disk and store them in memory so we don't have to do so multiple times
in_degree_sequences <- vector('list', nrow(languages))
for (i in seq(from=1, to=nrow(languages))){
  in_degree_sequences[i] <- read.table(languages$file[i], header = FALSE)
}
```

```{r}
lang_stats <- lapply(in_degree_sequences, 
                     function(x) list(N=length(x), 
                                      M=sum(x),
                                      max=max(x),
                                      M_prime=sum(log(x)),
                                      C=sum(sapply(seq(from=1, to=length(x), by=1), 
                                            function(i) sum(sapply(seq(from=1, to=x[i], by=1), function(j) log(j)))))))
```

```{r, echo=FALSE}
# Define the minus log likelihood functions for the different probaiblity mass functions to be passed to the optimizer
models <- c('Poisson', 'Geometric', 'Zeta_2', 'Zeta', 'Right-truncated Zeta')

generate_minus_log_likelihoods <- function(stats) {
  c(
    # Displaced Poisson
    function (lambda) { stats$N*(lambda + log(1 - exp(-lambda))) + stats$C - stats$M*log(lambda) },
    
    # Displaced Geometric
    function (q) { (stats$N - stats$M)*log(1-q) - stats$N*log(q) },
    
    # Zeta with gamma=2
    #function() { 2*stats$M_prime + stats$N*log((pi^2)/6) },
    
    # Zeta
    function(gamma) { stats$M_prime*gamma + stats$N*log(zeta(gamma))} ,
    
    # Right-truncated Zeta
    function (gamma, k_max) { gamma*stats$M_prime + stats$N*log(sum(sapply(seq(from=1, to=k_max, by=1), function(x) x^(-gamma)))) }
  )
}

start_parameters <- c(
  function(stats) { list( lambda=stats$M/stats$N ) },
  function(stats) { list( q=stats$N/stats$M ) },
  #function(stats) { list( NA ) },
  function(stats) { list( gamma=2 )},
  function(stats) { list( gamma=2, k_max=stats$max )}
)

lower_bounds <- c(
  function(stats) { c(1.0000001) },
  function(stats) { c(0.0000001) },
  #function(stats) { c(1.9999999) },
  function(stats) { c(1.0000001) },
  function(stats) { NA }
)

upper_bounds <- c(
  function(stats) { NA },
  function(stats) { c(0.9999999) },
  #function(stats) { c(2) },
  function(stats) { NA },
  function(stats) { c(NA, k_max=stats$N) } #This does not work with anything below N
)
```

```{r, echo = FALSE}
calculate_likelihoods <- function(stats) {
  minus_log_likelihood <- generate_minus_log_likelihoods(stats)
  lapply(seq(from=1, to=length(models)-1, by=1), function(i) {
          mle(minus_log_likelihood[[i]],
              start = start_parameters[[i]](stats),
              method = "L-BFGS-B",
              lower = lower_bounds[[i]](stats),
              upper = upper_bounds[[i]](stats)
          )
        })
}

mle_attributes <- lapply(lang_stats, function(x) lapply(calculate_likelihoods(x), function(l) attributes(summary(l))))
```

```{r, echo=FALSE}
# Apply generate_language_summary to every entry in the list of language in-degrees to generate the summary for every language. Use do.call to pass each summary to rbind as a parameter, that way the vectors are concatenated vertically
summary_df <- data.frame(do.call(rbind, lapply(lang_stats, function(x) c(x$N, x$max, x$M/x$N, x$N/x$M))), row.names=languages$language)

kable(summary_df, col.names=c('N', 'Max Degree', 'M/N', 'N/M'), booktabs=T, linesep='', align='c', digits=4) %>%
  kable_styling(latex_options = "striped", full_width=T)
```

```{r}
parameters_df <- data.frame(do.call(rbind, lapply(mle_attributes, function(x) unlist(lapply(x, function(x) x$coef[,1])))), row.names=languages$language)

kable(parameters_df,  col.names=c("lambda", 'q', 'gamma_1', 'gamma_2', 'k_{max}'), booktabs=T, linesep='', align='c', digits=4) %>%
  kable_styling(latex_options = "striped", full_width=T)
```


```{r}
calculate_AIC <- function(m2logL, K, N){
  m2logL + 2*K*N/(N-K-1)
}
```

```{r}
lapply(mle_attributes, function(x) sapply(unlist(lapply(x, function(x) x$m2logL)))
```


```{r}
# Function to write the languages summary (Table 2) from the data retrieved in previous chunk
write_summary_3 <- function(row, index) {
   # Generate the language summary (corresponding to a table row) by concatenating the following fields (Language name must be accessed)
   # | Language | poisson | geometric | zeta | right_truncated_zeta |
  k_used <- as.numeric(parameters$k_max[index])
  n_used <- length(row)
  cat(row$Language,
       get_AIC(as.numeric(row$poisson), k_used, n_used),
       get_AIC(as.numeric(row$geometric), k_used, n_used),
       get_AIC(as.numeric(row$zeta_gamma_2), k_used, n_used),
       get_AIC(as.numeric(row$zeta), k_used, n_used),
       get_AIC(as.numeric(row$rtrunc_zeta), k_used, n_used),
       "\n")
}
```

```{r}
for (i in seq(from=1, to=nrow(models))){
  write_summary_3(models[i,], i)
}
kable(models, "latex", col.names=colnames(models), booktabs=T, linesep='', align='c', digits=4) %>%
  kable_styling(latex_options = "striped", full_width=T)
```

