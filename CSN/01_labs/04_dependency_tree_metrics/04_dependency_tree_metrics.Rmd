---
title: "Lab 04 - Non-linear regression on dependency trees"
author: "Francisco Javier Jurado, Roger Pujol Torramorell"
date: "October 29, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE}
# Load and install necessary packages
requiredPackages <- c("knitr", "rstudioapi", "kableExtra", "stats")

for (pac in requiredPackages) {
    if(!require(pac,  character.only=TRUE)){
        install.packages(pac, repos="http://cran.rstudio.com")
        library(pac,  character.only=TRUE)
    }
}
rm(pac)
rm(requiredPackages)

# set pwd to current directory, must load rstudioapi before.
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
```

```{r, echo=FALSE,include=FALSE}
# Possible solutions for heteroscedasticity: work on smoothed versions of the data: eg. average all points for a value x and work on that

# plot everything to be plotted
# Check soundness by generating perfect synthetic data and checking the fit against it. R doesnt like perfect function, some error must be added to the actual data

# replace d with a z score transformation of d
# This transform could help to reduce noise in te data

```

```{r, echo=FALSE}
  # Read the list of languages from file
filename_suffix <- "_dependency_tree_metrics.txt"
language_list <- as.vector(read.table("data/language_list.txt", header = FALSE)$V1)

# Push the in-degree sequences and theh list of entries to the global scope
dep_tree_cols <- c('n', 'k^2', 'd')
dep_tree_metric_seqs <- lapply(language_list, function(x) data.frame(read.table(paste("data/", x, filename_suffix, sep=''), header = FALSE, col.names=dep_tree_cols)))

avg_seqs <- lapply(dep_tree_metric_seqs, function(x) aggregate(x, list(x$n), mean))
```

# Results
## On the validity of the inputs
```{r, echo=FALSE}
valid_k.2 <- lapply(dep_tree_metric_seqs, function(x) (4-(6/x$n) <= x$k.2) & (x$k.2 <= x$n-1))
valid_d <- lapply(dep_tree_metric_seqs, function(x) (x$k.2*x$n/(8*(x$n-1)) + 1/2 <= x$d) & (x$d <= x$n-1))
```
## Results
The first table in this results section summarizes the properties of the degree sequences, in particular the sample size and the mean and standard deviation of both the number of vertices $n$ and the mean dependency length $d$: 
```{r, echo=FALSE}
summary_cols <- c('N', 'mean_n', 'sd_n', 'mean_d', 'sd_d')
metric_stats <- lapply(dep_tree_metric_seqs, function(x) list(
                    N=length(x),
                    mean_n=mean(x$n),
                    sd_n=sd(x$n),
                    mean_d=mean(x$d),
                    sd_d=sd(x$d)))

summary_df <- data.frame(do.call(rbind, lapply(metric_stats, function(x) c(x$N, x$mean_n, x$sd_n, x$mean_d, x$sd_d))), row.names=language_list)
kable(summary_df, 'latex', col.names=summary_cols, booktabs=T, linesep='', align='c', digits=4) %>%
  kable_styling(latex_options="striped", full_width=F)
```
TODO: COMMENT THE TABLE
Before going any further it is a good practice to check what the data looks like so let's plot the mean depencency length $d$ vs the number of vertices $n$:
```{r, echo=FALSE, fig.width=16, fig.height=18}
old.par <- par(mfrow=c(ceiling(length(dep_tree_metric_seqs)/3), 3))
par(mar=c(4,4,2,2))
for (i in seq(from=1, to=length(dep_tree_metric_seqs), by=1)) {
  plot(x=dep_tree_metric_seqs[[i]]$n,
       y=dep_tree_metric_seqs[[i]]$d,
       main=language_list[[i]],
       #log='xy',
       xlab='# vertices',
       ylab='mean dependency length',
       col='blue')
}
```
We would like to check for any possible power-law dependencies and we can do so by plotting data taking logs on both axes:
```{r, echo=FALSE, fig.width=16, fig.height=18}
old.par <- par(mfrow=c(ceiling(length(dep_tree_metric_seqs)/3), 3))
par(mar=c(4,4,2,2))
for (i in seq(from=1, to=length(dep_tree_metric_seqs), by=1)) {
  plot(x=dep_tree_metric_seqs[[i]]$n,
       y=dep_tree_metric_seqs[[i]]$d,
       main=language_list[[i]],
       log='xy',
       xlab='log(# vertices)',
       ylab='log(mean dependency length)',
       col='blue')
}
```
Note that rather than applying the log to the data itself we have set the plot axes to logarithmic, distributing the ticks in a log fashion. We can now observe that the plots suggest a power-law despite the large amount of dispersion.

A way to deal with this dispersion and get a clearer intuition on the underlying trend is to average the mean length for a given number of vertices:
```{r, echo=FALSE, fig.width=16, fig.height=18}
old.par <- par(mfrow=c(ceiling(length(dep_tree_metric_seqs)/3), 3))
par(mar=c(4,4,2,2))

for (i in seq(from=1, to=length(dep_tree_metric_seqs), by=1)) {
  plot(x=avg_seqs[[i]]$n,
       y=avg_seqs[[i]]$d,
       main=language_list[[i]],
       #log='xy',
       xlab='# vertices',
       ylab='avg mean dependency length',
       col='blue')
}
```
Although there is stil a significant amount of dispersion for larger values of $n$, we have a way clearer view of the distribution shape. By plotting the same averaged points on log-log axes:
```{r, echo=FALSE, fig.width=16, fig.height=18}
old.par <- par(mfrow=c(ceiling(length(dep_tree_metric_seqs)/3), 3))
par(mar=c(4,4,2,2))

for (i in seq(from=1, to=length(dep_tree_metric_seqs), by=1)) {
  plot(x=avg_seqs[[i]]$n,
       y=avg_seqs[[i]]$d,
       main=language_list[[i]],
       log='xy',
       xlab='log(# vertices)',
       ylab='log(avg mean dependency length)',
       col='blue')
}
```
The data points form an almost straight line in the log-log plot (again with dispersion when $n$ gets large) so we have reasonable evidence to believe they follow a power-law distribution.  

We now want to compare how far the real scaling of $d$ is from the one existing at a random linear arrangement. For that purpose we can compare the points to the averaged ones and the expected mean length, given by $E[\langle d \rangle] = (n+1)/3$. Plotting that in a regular and double logarithmic scale:
```{r, echo=FALSE, fig.width=16, fig.height=18}
old.par <- par(mfrow=c(ceiling(length(dep_tree_metric_seqs)/3), 3))
par(mar=c(4,4,2,2))
for (i in seq(from=1, to=length(dep_tree_metric_seqs), by=1)) {
  plot(x=dep_tree_metric_seqs[[i]]$n,
       y=dep_tree_metric_seqs[[i]]$d,
       main=language_list[[i]],
       #log='xy',
       xlab='log(# vertices)',
       ylab='log(mean dependency length)',
       col='light blue')
  # Add the average sequence values
  lines(x=avg_seqs[[i]]$n,
        y=avg_seqs[[i]]$d,
        col="blue")
  
  # Add the expected mean length
  lines(x=avg_seqs[[i]]$n,
        y=(avg_seqs[[i]]$n+1)/3,
        col="red")
  
  legend("topleft", legend=c("Avg mean length", "Expected mean length"),
     col=c('blue', 'red'), lty=3, pch=1, cex=1.4)
}
```

```{r, echo=FALSE, fig.width=16, fig.height=18}
old.par <- par(mfrow=c(ceiling(length(dep_tree_metric_seqs)/3), 3))
par(mar=c(4,4,2,2))
for (i in seq(from=1, to=length(dep_tree_metric_seqs), by=1)) {
  plot(x=dep_tree_metric_seqs[[i]]$n,
       y=dep_tree_metric_seqs[[i]]$d,
       main=language_list[[i]],
       log='xy',
       xlab='log(# vertices)',
       ylab='log(mean dependency length)',
       col='light blue')
  # Add the average sequence values
  lines(x=avg_seqs[[i]]$n,
        y=avg_seqs[[i]]$d,
        col="blue")
  
  # Add the expected mean length
  lines(x=avg_seqs[[i]]$n,
        y=(avg_seqs[[i]]$n+1)/3,
        col="red")
  
  legend("topleft", legend=c("Avg mean length", "Expected mean length"),
     col=c('blue', 'red'), lty=3, pch=1, cex=1.4)
}
```

```{r, echo=FALSE}

# Model parameters list
params_ensemble <- list(
  c('b'),       # Model 1
  c('a', 'b'),  # Model 2
  c('a','c'),   # Model 3
  c('a')        # Model 4
)

# Model formulas list
formula_ensemble <- c(
  d~(n/2)^b,     # Model 1
  d~a*n^b,       # Model 2
  d~a*exp(c*n),  # Model 3
  d~a*log(n)     # Model 4
)

# Log transform of the model formulas list
log_formulas <- c (
  log(d)~log(n/2) + 0, # Model 1
  log(d)~log(n),   # Model 2
  log(d)~n,        # Model 3
  log(d)~1*log(log(n)) # Model 4
)
```

```{r, echo=FALSE}
# Outer loop to iterate over the sequences
initial_values <- lapply( dep_tree_metric_seqs, function(seq) {
  # Inner loop 1 to iterate over the formulas
  lapply( seq(from=1, to=length(log_formulas), by=1), function(i) {
    lm <- lm(log_formulas[[i]], seq)
    # Inner loop 2 to iterate over the parameters of each model
    structure(sapply( seq(from=1, to=length(params_ensemble[[i]]), by=1), function(j)
      # Check if the parameter corresponds to "a", if so reverse the log transform by exponentiating it
      if(params_ensemble[[i]][[j]] == 'a') exp(coef(lm)[[j]]) else coef(lm)[[j]]), names=params_ensemble[[i]])
  })
})
```

```{r}
nl_models <- lapply( seq(from=1, to=length(dep_tree_metric_seqs), by=1), function(i) {
  lapply( seq(from=1, to=length(formula_ensemble), by=1), function(j) {
    nlm <- nls(
      formula=formula_ensemble[[j]],
      data=dep_tree_metric_seqs[[i]],
      start=initial_values[[i]][[j]],
      trace=FALSE
    )
  })
})
```
