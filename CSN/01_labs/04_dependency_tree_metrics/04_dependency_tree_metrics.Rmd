---
output:
  pdf_document: default
  html_document: default
---
 ---
title: "Lab 04 - Non-linear regression on dependency trees"
author: "Francisco Javier Jurado, Roger Pujol Torramorell"
date: "October 29, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE}
# Load and install necessary packages
requiredPackages <- c("knitr", "rstudioapi", "kableExtra", "stats")

for (pac in requiredPackages) {
    if(!require(pac,  character.only=TRUE)){
        install.packages(pac, repos="http://cran.rstudio.com")
        library(pac,  character.only=TRUE)
    }
}
rm(pac)
rm(requiredPackages)

# set pwd to current directory, must load rstudioapi before. Need to check availability of API to avoid issues when knitting
if (rstudioapi::isAvailable()) setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

```

```{r, echo=FALSE}
# Model Class definition
model <- setRefClass("model", fields=list(label="character", params="ANY", f="function", formula="ANY", log_formula="ANY"))

# List of models. Each model is an object. f returns the model function given its parameters to be able to generate points
model_ensemble <- list(
  model(label="0",
        params=c(),
        f=function() { function(n) n/3 + 1/3 },
        formula=NA,
        log_formula=NA),
  
  model(label="1",
        params=c('b'),
        f=function(b) { function(n) (n/2)^b },
        formula=d~(n/2)^b,
        log_formula=log(d)~log(n/2) + 0),
  
  model(label="2",
        params=c('a', 'b'),
        f=function(a, b) { function(n) a*n^b },
        formula=d~a*n^b,
        log_formula=log(d)~log(n)),
  
  model(label="3",
        params=c('a','c'),
        f=function(a, c) { function(n) a*exp(c*n) },
        formula=d~a*exp(c*n),
        log_formula=log(d)~n),
  
  model(label="4",
        params=c('a'),
        f=function(a) { function(n) a*log(n) },
        formula=d~a*log(n),
        log_formula=log(d)~1*log(log(n)))
  )
```

```{r, echo=FALSE}
generate_nlms <- function(seqs, ensemble) {
  lapply( seqs, function(seq) {         # Outer loop to iterate over the dependency sequences
    lapply(ensemble, function(model) {  # Inner loop to iterate over the models
      if (length(model$params) > 0) {
        lm <- lm(model$log_formula, seq)
        initial_values <- structure(lapply(1:length(model$params), function(i)
          if (model$params[i] == "a") exp(coef(lm)[[i]]) else coef(lm)[[i]] ), names=model$params)
        nls( formula=model$formula, data=seq, start=initial_values, trace=FALSE)
      } else NA
    })
  })
}

calculate_deviances <- function(seqs, models) {
  lapply (1:length(seqs), function(i) {
    sapply(1:length(models[[i]]), function(j) {
      if (!is.na(models[[i]][j])) { deviance(models[[i]][[j]]) }
      else { sum( (seqs[[i]]$d - (seqs[[i]]$n+1)/3)^2) }
    })
  })
}

calculate_AICs <- function(seqs, models, devs) {
  lapply (1:length(seqs), function(i) {
    sapply(1:length(models[[i]]), function(j) {
      if (!is.na(models[[i]][j])) { AIC(models[[i]][[j]]) }
      else {
        n <- length(seqs[[i]]$n)
        n*log(2*pi) + n*log(devs[[i]][[j]]/n) + n + 2
      }
    })
  })
}

# This pushes tables to the global context
generate_models_and_measures <- function (seqs, ensemble) {
  nlms <<- generate_nlms(seqs=seqs, ensemble=ensemble)
  deviances <<- calculate_deviances(seqs, nlms)
  AICs <<- calculate_AICs(seqs, nlms, deviances)
}

plot_grid <- function(data, labels, xlab, ylab, color="blue", lines=list(), line_colors=c(), log=FALSE) {
  old.par <- par(mfrow=c(ceiling(length(data)/3), 3))
  par(mar=c(4,4,2,2))
  for (i in 1:length(data)) {
    plot(x=data[[i]]$n,
         y=data[[i]]$d,
         main=labels[[i]],
         log= if(log) "xy" else '',
         xlab=xlab,
         ylab=ylab,
         col=color)
    for (j in seq_along(lines)) {
        lines(x=lines[[j]][[i]]$n,
        y=lines[[j]][[i]]$d,
        col=line_colors[[j]])
    }
  }
}
```


```{r, echo=FALSE,include=FALSE}
# Possible solutions for heteroscedasticity: work on smoothed versions of the data: eg. average all points for a value x and work on that

# plot everything to be plotted
# Check soundness by generating perfect synthetic data and checking the fit against it. R doesnt like perfect function, some error must be added to the actual data

# replace d with a z score transformation of d
# This transform could help to reduce noise in te data

```

```{r, echo=FALSE}
  # Read the list of languages from file
filename_suffix <- "_dependency_tree_metrics.txt"
language_list <- as.vector(read.table("data/language_list.txt", header = FALSE)$V1)

# Push the in-degree sequences and theh list of entries to the global scope
dep_tree_cols <- c('n', 'k^2', 'd')
metric_seqs <- structure(lapply(language_list, function(x) data.frame(read.table(paste("data/", x, filename_suffix, sep=''), header = FALSE, col.names=dep_tree_cols))),
                         names=language_list)

avg_seqs <- lapply(metric_seqs, function(x) aggregate(x, list(x$n), mean))
```

# Results

## On input validity [ WIP ]
```{r, echo=FALSE}
valid_k.2 <- lapply(metric_seqs, function(x) (4-(6/x$n) <= x$k.2) & (x$k.2 <= x$n-1))
valid_d <- lapply(metric_seqs, function(x) (x$k.2*x$n/(8*(x$n-1)) + 1/2 <= x$d) & (x$d <= x$n-1))
```
## Properties summary
The first table in this results section summarizes the properties of the degree sequences, in particular the sample size and the mean and standard deviation of both the number of vertices $n$ and the mean dependency length $d$:
```{r, echo=FALSE}
summary_cols <- c('N', 'mean_n', 'sd_n', 'mean_d', 'sd_d')
metric_stats <- lapply(metric_seqs, function(x) list(
                    N=length(x$n),
                    mean_n=mean(x$n),
                    sd_n=sd(x$n),
                    mean_d=mean(x$d),
                    sd_d=sd(x$d)))

summary_df <- data.frame(do.call(rbind, lapply(metric_stats, function(x) c(x$N, x$mean_n, x$sd_n, x$mean_d, x$sd_d))), row.names=language_list)
kable(summary_df, col.names=summary_cols, booktabs=T, linesep='', align='c', digits=4) %>%
  kable_styling(latex_options="striped", full_width=F)
```
TODO: COMMENT THE TABLE

\newpage
## Preliminary visualization
Before going any further it is a good practice to check what the data looks like so let's plot the mean depencency length $d$ vs the number of vertices $n$:

```{r, echo=FALSE, fig.width=16, fig.height=18}
plot_grid(metric_seqs, language_list, '# vertices', 'mean dependency length')
```
\newpage
We would like to check for any possible power-law dependencies and we can do so by plotting data taking logs on both axes:

```{r, echo=FALSE, fig.width=16, fig.height=18}
plot_grid(metric_seqs, language_list, 'log(# vertices)', 'log(mean dependency length)', log=TRUE)
```
Note that rather than applying the log to the data itself we have set the plot axes to logarithmic, distributing the ticks in a log fashion. We can now observe that the plots suggest a power-law despite the large amount of dispersion.

\newpage
## Checking for heteroscedasticity
We have seen in the preliminary plots that there is a One of the assumptions of non-linear regression is homoscedasticity, so before generating our models we need to make sure it holds.

```{r, echo=FALSE, fig.width=16, fig.height=18}
# Careful, this contains
var_seqs <- lapply(1:length(metric_seqs), function(i) data.frame(n=avg_seqs[[i]]$n, d=sapply(avg_seqs[[i]]$n, function(x) var( metric_seqs[[i]][metric_seqs[[i]]$n == x,]$d) ) ))
plot_grid(var_seqs, language_list, '# vertices', 'mean dependency length variance')
```

Note that in order to calculate the variance for a given value of $n$ we need more than one data point so those $n$ with a single point have been omitted.

\newpage
A way to deal with this dispersion and get a clearer intuition on the underlying trend is to average the mean length for a given number of vertices:

```{r, echo=FALSE, fig.width=16, fig.height=18}
plot_grid(avg_seqs, language_list, '# vertices', 'avg mean dependency length')
```
Although there is stil a significant amount of dispersion for larger values of $n$, we have a way clearer view of the distribution shape. By plotting the same averaged points on log-log axes:

```{r, echo=FALSE, fig.width=16, fig.height=18}
plot_grid(avg_seqs, language_list, 'log(# vertices)', 'log(avg mean dependency length)', log=TRUE)
```
The data points form an almost straight line in the log-log plot (again with dispersion when $n$ gets large) so we have reasonable evidence to believe they follow a power-law distribution.  

We now want to compare how far the real scaling of $d$ is from the one existing at a random linear arrangement. For that purpose we can compare the points to the averaged ones and the expected mean length, given by $E[\langle d \rangle] = (n+1)/3$. Plotting that in a regular and double logarithmic scale:

```{r, echo=FALSE, fig.width=16, fig.height=18}
plot_grid(metric_seqs, language_list, 'log(# vertices)', 'log(avg mean dependency length)', color="light blue",
          lines=list(avg_seqs, lapply(avg_seqs, function(x) list("n"=x$n, "d"=(x$n+1)/3))), line_colors=c("blue", "red"))
```

```{r, echo=FALSE, fig.width=16, fig.height=18}
plot_grid(metric_seqs, language_list, 'log(# vertices)', 'log(avg mean dependency length)', color="light blue", log=TRUE,
          lines=list(avg_seqs, lapply(avg_seqs, function(x) list("n"=x$n, "d"=(x$n+1)/3))), line_colors=c("blue", "red"))
```

## On correctness
Before applying our fitting method to the real data we would like to make sure they work properly. For that purpose we will generate a set of synthetic sequences using the functions from our model ensemble, fit them and then check if the output of our model selection process matches the original data. As parameters we will arbitrarily choose (based on observations of the values obtained when fitting the real sequences) $a = 0.8$, $b=0.5$ and $c=0.01$. We start by generating a instance of each model.:

```{r, echo=FALSE}
test_params <- list(c(), c(b=0.5), c(a=0.8, b=0.5), c(a=0.8, c=0.01), c(a=0.8))
num_test_observations = 200
test_functions <- lapply(1:length(test_params), function(i) do.call(model_ensemble[[i]]$f, as.list(test_params[[i]])))
# We need to add omse error to the function so the estimator can converge.
test_seqs <- lapply(test_functions, function(f) data.frame(
  n=1:num_test_observations,
  d=sapply(1:num_test_observations, function(i) f(i)) + rnorm(num_test_observations, sd=0.05)))
```

```{r, echo=FALSE, fig.width=16}
plot_grid(test_seqs, lapply(model_ensemble, function(x) paste("Model ", x$label)), xlab='n', ylab='f(n)')
```

```{r, echo=FALSE}
generate_models_and_measures(test_seqs, model_ensemble)
kable(data.frame(do.call(rbind, AICs), row.names=sapply(model_ensemble, function(x) x$label)), col.names=sapply(model_ensemble, function(x) x$label), booktabs=T, linesep='', align='c', digits=2) %>%
  kable_styling(latex_options="striped", full_width=F)
```

# <NOTE> Comparison between non-average and average fitted lines. For non-averaged it is always model 2, for averaged is not always the case

```{r, echo=FALSE}
fitted_params <- lapply(nlms, function(x) lapply(x, function(nlm) if(!is.na(nlm)[1]) coef(nlm) else c()))
best_models <- lapply(AICs, function(x) which.min(as.vector(x)))
best_coefs <- lapply(1:length(nlms), function(i) fitted_params[[i]][[ as.numeric(best_model[i]) ]])
```


```{r, echo=FALSE}
fitted_test_functions <- lapply (1:length(test_functions), function(i) data.frame(
  n=1:num_test_observations,
  d=sapply (1:num_test_observations, function(n)
    do.call(do.call(model_ensemble[[ best_model [[i]] ]]$f, as.list(best_coefs[[i]])), list(n))
  )
))
```


```{r, echo=FALSE, fig.width=16}
plot_grid(test_seqs, lapply(model_ensemble, function(x) paste("Model ", x$label)), xlab='n', ylab='f(n)', color="light blue",
          lines=list(fitted_test_functions), line_colors=c("red"))
```

